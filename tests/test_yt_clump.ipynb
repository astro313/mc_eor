{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yt clump finder was initially described in \n",
    "http://adsabs.harvard.edu/abs/2009ApJ...691..441S , but it's changed \n",
    "since then.  What it does now is decompose into non-overlapping tiles \n",
    "(stored in a kd-tree), identify contours within a tile, and then \n",
    "connect them across tiles.  It does this with an upper and lower bound \n",
    "on a field value, and looking for topologically connected sets. \n",
    "\n",
    "With yt, connected sets can be identified. This enables the location and analysis of **a hierarchy of\n",
    "clumps**; in star formation, for instance, this allows the construction of diagrams **describing the density\n",
    "at which fragmentation occurs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import yt\n",
    "from yt.analysis_modules.level_sets.api import *\n",
    "\n",
    "ds = yt.load(\"output/output_00028/info_00028.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat output/output_00028/*csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = [0.53103, 0.51031000000000004, 0.50402000000000002]\n",
    "region_size = 0.0015\n",
    "up_vector = [0.10255487134299716, 0.059509123032244614, 0.99294569974382518]\n",
    "\n",
    "distance = 0.00075\n",
    "far_cut_depth = 0.00075\n",
    "\n",
    "data_source = ds.sphere(center, region_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.current_time, ds.current_redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_source.get_field_parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_source([\"density\"]))\n",
    "\n",
    "sp = data_source\n",
    "\n",
    "# Print things in a more human-friendly manner: one density at a time\n",
    "print(\"(x,  y,  z) Density\")\n",
    "print(\"-----------------------\")\n",
    "for i in range(sp[\"density\"].size):\n",
    "    print(\"(%f,  %f,  %f)    %f\" %\n",
    "          (sp[\"x\"][i], sp[\"y\"][i], sp[\"z\"][i], sp[\"density\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = ds.all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx['density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_source.get_data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assuming it's disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.disk?\n",
    "# center, normal, radius, height, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yt.analysis_modules.level_sets.api import Clump, find_clumps, get_lowest_clumps\n",
    "    \n",
    "data_source = ds.disk(center, up_vector, region_size, (far_cut_depth + distance))\n",
    "\n",
    "c_min = 10**np.floor(np.log10(data_source['density']).min()  )\n",
    "c_max = 10**np.floor(np.log10(data_source['density']).max()+1)\n",
    "\n",
    "master_clump = Clump(data_source, 'density')\n",
    "master_clump.add_validator(\"min_cells\", 20)\n",
    "\n",
    "find_clumps(master_clump, c_min, c_max, 2.0)\n",
    "leaf_clumps = get_lowest_clumps(master_clump)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prj = yt.ProjectionPlot(ds, 'z', 'density', center='c', width=(20, 'kpc'))\n",
    "prj.annotate_clumps(leaf_clumps)\n",
    "prj.save('clumps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the RAMSES AMR mesh isn't too highly refined or the region of interest isn't too huge, one way to get it to work would be to interpolate the data using a covering_grid or arbitrary_grid yt data object to a uniform resolution grid. \n",
    "\n",
    "Then reload the uniform resolution data using the yt.load_uniform_grid function, and run the clump finder on the reloaded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.max_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.min_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Why is the min_level non-zero? or just 1?\n",
    "\n",
    "A: starting point non-zero or 1.\n",
    "\n",
    "### Q: Also, why isn't max_level 17 (from the info_...txt file)? \n",
    "\n",
    "levelmin    =          8\n",
    "levelmax    =         17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims=ds.domain_dimensions\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.covering_grid?        # with no interpolation or smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# level:  The resolution level data to which data will be gridded. Level 0 is the root grid dx for that dataset.\n",
    "cube_lvl0 = ds.covering_grid(level=0,  #  sampling just the lowest level data\n",
    "                        left_edge=[0,0.0,0.0],\n",
    "                        dims=ds.domain_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cube_lvl0['density'].shape)\n",
    "print(cube_lvl0['density'][128,128,128])\n",
    "# del cube_lvl0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a covering grid that spans two child grids of a single parent grid (with no interpolation or smoothing).\n",
    "\n",
    "Where it is covered only by the parent grid, the cells from the parent grid will be duplicated (appropriately) to fill the covering grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# level = 2\n",
    "# dims = ds.domain_dimensions * ds.refine_by**level\n",
    "\n",
    "cube_lvl2 = ds.covering_grid(level=2, # grid that spans two child grids of a single parent grid\n",
    "                        left_edge=[0,0.0,0.0],\n",
    "                        dims=ds.domain_dimensions * 2**2)   # increase the resolution of our output array by a factor of 2^2 in each direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cube_lvl2['density'].shape)\n",
    "print(cube_lvl2['density'][512,512,512])\n",
    "del cube_lvl2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different types of covering grids: unsmoothed and smoothed. Smoothed grids will be filled through a cascading interpolation process; they will be filled at level 0, interpolated to level 1, filled at level 1, interpolated to level 2, filled at level 2, etc. This will help to reduce edge effects. Unsmoothed covering grids will not be interpolated, but rather values will be duplicated multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample our dataset from above with a smoothed covering grid in order to reduce edge effects\n",
    "cube_lvl2_s = ds.smoothed_covering_grid(2, [0.0, 0.0, 0.0,],\n",
    "                                       ds.domain_dimensions * 2**2)\n",
    "\n",
    "print(cube_lvl2_s['density'].shape)\n",
    "\n",
    "# look at density at central location\n",
    "print(cube_lvl2_s['density'][512,512,512])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.log10(cube_lvl2_s['density'].flatten()))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.log10(cube_lvl0['density'].flatten()))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the level 0 (coarsest) covering grid to test out clump find function in yt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yt.analysis_modules.level_sets.api import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# field to be used for contouring\n",
    "field = (\"density\")        # test w/ \"density\" for now.\n",
    "\n",
    "# multiplicative interval between contours.\n",
    "step = 2.0\n",
    "\n",
    "# set some sane min/max values between which we want to find contours.\n",
    "# so that it won't look for\n",
    "# contours connected below or above these threshold values.\n",
    "c_min = 10**np.floor(np.log10(cube_lvl0[field]).min()  )\n",
    "c_max = 10**np.floor(np.log10(cube_lvl0[field]).max()+1)\n",
    "\n",
    "# Now find our 'base' clump -- this \"base clump\" just covers the whole domain.\n",
    "master_clump = Clump(cube_lvl0, field)\n",
    "\n",
    "# Add a \"validator\" to weed out clumps with less than 20 cells.\n",
    "# As many validators can be added as you want.\n",
    "master_clump.add_validator(\"min_cells\", 20)\n",
    "\n",
    "# Calculate center of mass for all clumps.\n",
    "master_clump.add_info_item(\"center_of_mass\")\n",
    "\n",
    "# Begin clump finding.\n",
    "find_clumps(master_clump, c_min, c_max, step)\n",
    "\n",
    "# Save the clump tree as a reloadable dataset\n",
    "fn = master_clump.save_as_dataset(fields=[\"density\", \"particle_mass\"])\n",
    "\n",
    "# We can traverse the clump hierarchy to get a list of all of the 'leaf' clumps\n",
    "leaf_clumps = get_lowest_clumps(master_clump)\n",
    "\n",
    "# If you'd like to visualize these clumps, a list of clumps can be supplied to\n",
    "# the \"clumps\" callback on a plot.  First, we create a projection plot:\n",
    "prj = yt.ProjectionPlot(ds, 2, field, center='c', width=(20,'kpc'))\n",
    "\n",
    "# Next we annotate the plot with contours on the borders of the clumps\n",
    "prj.annotate_clumps(leaf_clumps)\n",
    "\n",
    "# Save the plot to disk.\n",
    "prj.save('clumps')\n",
    "\n",
    "# Reload the clump dataset.\n",
    "cds = yt.load(fn)\n",
    "\n",
    "# Clump annotation can also be done with the reloaded clump dataset.\n",
    "\n",
    "# Remove the original clump annotation\n",
    "prj.annotate_clear()\n",
    "\n",
    "# Get the leaves and add the callback.\n",
    "leaf_clumps_reloaded = cds.leaves\n",
    "prj.annotate_clumps(leaf_clumps_reloaded)\n",
    "prj.save('clumps_reloaded')\n",
    "\n",
    "# Query fields for clumps in the tree.\n",
    "print (cds.tree[\"clump\", \"center_of_mass\"])\n",
    "print (cds.tree.children[0][\"grid\", \"density\"])\n",
    "print (cds.tree.children[1][\"all\", \"particle_mass\"])\n",
    "\n",
    "# Get all of the leaf clumps.\n",
    "print (cds.leaves)\n",
    "print (cds.leaves[0][\"clump\", \"cell_mass\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
